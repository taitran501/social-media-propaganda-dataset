{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.058806Z",
     "iopub.status.busy": "2025-08-08T10:38:12.058504Z",
     "iopub.status.idle": "2025-08-08T10:38:12.063893Z",
     "shell.execute_reply": "2025-08-08T10:38:12.063209Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.058785Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install emoji regex pandas unicodedata fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.065280Z",
     "iopub.status.busy": "2025-08-08T10:38:12.065033Z",
     "iopub.status.idle": "2025-08-08T10:38:12.395805Z",
     "shell.execute_reply": "2025-08-08T10:38:12.394851Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.065238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import regex\n",
    "import emoji\n",
    "import unicodedata\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.396936Z",
     "iopub.status.busy": "2025-08-08T10:38:12.396611Z",
     "iopub.status.idle": "2025-08-08T10:38:12.782459Z",
     "shell.execute_reply": "2025-08-08T10:38:12.781758Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.396916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Head ========\n",
      "                                             summary  \\\n",
      "0  1. Nội dung sơ lược: Bài viết chỉ trích Phạm V...   \n",
      "1  1. Nội dung sơ lược: Bài viết chỉ trích Phạm V...   \n",
      "2  1. Nội dung sơ lược: Bài viết chỉ trích Phạm V...   \n",
      "3  1. Nội dung sơ lược: Bài viết chỉ trích Phạm V...   \n",
      "4  1. Nội dung sơ lược: Bài viết chỉ trích Phạm V...   \n",
      "\n",
      "                                         comment_raw            label  \n",
      "0  luận điệu của bọn phản động, sỏ lá, 3/// viết ...  KHONG_PHAN_DONG  \n",
      "1  vậy ông bảo đại, ông diệm, ông thiệu là đảng v...  KHONG_PHAN_DONG  \n",
      "2                              muôn đời của đám 3///  KHONG_PHAN_DONG  \n",
      "3  già rồi mà đần vậy cháu ? cộng sản đánh mỹ, đá...  KHONG_PHAN_DONG  \n",
      "4  đúng là 3/// xỏ lá, bác hồ mất nên các bác khó...  KHONG_PHAN_DONG  \n",
      "\n",
      "======== Tail ========\n",
      "                                                 summary  \\\n",
      "17646  1. Nội dung sơ lược: Câu chuyện ngụ ngôn về cu...   \n",
      "17647  1. Nội dung sơ lược: Câu chuyện ngụ ngôn về cu...   \n",
      "17648  1. Nội dung sơ lược: Câu chuyện ngụ ngôn về cu...   \n",
      "17649  1. Nội dung sơ lược: Câu chuyện ngụ ngôn về cu...   \n",
      "17650  1. Nội dung sơ lược: Câu chuyện ngụ ngôn về cu...   \n",
      "\n",
      "                                             comment_raw            label  \n",
      "17646  ông bà nội bạn bị chôn sống thì tới đời con ch...  KHONG_LIEN_QUAN  \n",
      "17647                        vì đài dám nói lên sự thật?  KHONG_LIEN_QUAN  \n",
      "17648  sự thật gì? báo đài ngày nào chả đăng! thật cá...  KHONG_LIEN_QUAN  \n",
      "17649                   sự thật như nick của cháu vậy đó  KHONG_LIEN_QUAN  \n",
      "17650  con hoang được trại trẻ mồ côi nhận nuôi nó cò...  KHONG_LIEN_QUAN  \n",
      "\n",
      "======== Shape ========\n",
      "(17651, 3)\n",
      "\n",
      "======== Info ========\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17651 entries, 0 to 17650\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   summary      17651 non-null  object\n",
      " 1   comment_raw  17651 non-null  object\n",
      " 2   label        17651 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 413.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"/kaggle/input/eureka-version-dataset/final_raw.csv\")\n",
    "# df = pd.read_csv(\"/kaggle/input/eureka-version-dataset/v2_raw.csv\")\n",
    "df = pd.read_csv(\"/kaggle/input/eureka-version-dataset/final_raw_new.csv\")\n",
    "selected_df = df[['summary', 'comment_raw', 'label']]\n",
    "print(\"======== Head ========\")\n",
    "print(selected_df.head(5))\n",
    "print(\"\\n======== Tail ========\")\n",
    "print(selected_df.tail(5))\n",
    "\n",
    "print(\"\\n======== Shape ========\")\n",
    "print(selected_df.shape)\n",
    "\n",
    "print(\"\\n======== Info ========\")\n",
    "print(selected_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normalize Unicode (NFC) + lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.783966Z",
     "iopub.status.busy": "2025-08-08T10:38:12.783750Z",
     "iopub.status.idle": "2025-08-08T10:38:12.787609Z",
     "shell.execute_reply": "2025-08-08T10:38:12.787004Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.783949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_unicode_lower(text):\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Remove Emoji, links/HTML tags/mentions/hashtags/UI indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.788709Z",
     "iopub.status.busy": "2025-08-08T10:38:12.788487Z",
     "iopub.status.idle": "2025-08-08T10:38:12.811820Z",
     "shell.execute_reply": "2025-08-08T10:38:12.811056Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.788684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# emoji\n",
    "EMOTICON_PATTERNS = [\n",
    "    r\":\\)+\",       # :), :)), :))), ...\n",
    "    r\":\\(+\",       # :(, :((, ...\n",
    "    r\":v+\",        # :v, :vvv, ...\n",
    "    r\":V+\",        # :V, :VV, ...\n",
    "    r\"=+\\)+\",      # =), =)), ...\n",
    "    r\"=+\\(+\",      # =(, =((, ...\n",
    "    r\":d+\",        # :d, :dd\n",
    "    r\":p+\",        # :p, :pp\n",
    "    r\"<3+\",        # <3<3<3\n",
    "    r\"=+\\]+\",      # =], =]], =]]], ...\n",
    "    r\"=+\\[+\",      # =[, =[[, =[[[ ...\n",
    "    r\":>+\",        # :>, :>>, ...\n",
    "    r\":<+\",        # :<, :<<, ...\n",
    "    r\":\\(\\(\",      # :((\n",
    "    r\"=\\(\\(\",      # =((\n",
    "]\n",
    "\n",
    "EMOTICON_REGEX = re.compile(\"|\".join(EMOTICON_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "EMOJI_REGEX = re.compile(\n",
    "    \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"\n",
    "    u\"\\U0001F300-\\U0001F5FF\"\n",
    "    u\"\\U0001F680-\\U0001F6FF\"\n",
    "    u\"\\U0001F700-\\U0001F77F\"\n",
    "    u\"\\U0001F780-\\U0001F7FF\"\n",
    "    u\"\\U0001F800-\\U0001F8FF\"\n",
    "    u\"\\U0001F900-\\U0001F9FF\"\n",
    "    u\"\\U0001FA00-\\U0001FA6F\"\n",
    "    u\"\\U0001FA70-\\U0001FAFF\"\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\" \n",
    "    \"]+\", flags=re.UNICODE\n",
    ")\n",
    "\n",
    "def remove_emoji_emoticon(text):    \n",
    "    try:\n",
    "        text = emoji.replace_emoji(text, replace=\" \")\n",
    "    except:\n",
    "        text = EMOJI_REGEX.sub(\" \", text)\n",
    "    \n",
    "    # Xóa bằng regex\n",
    "    text = EMOTICON_REGEX.sub(\" \", text)\n",
    "    \n",
    "    # Loại bỏ khoảng trắng dư thừa\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# url, html, mention, hashtags, ui_indicators\n",
    "URL_REGEX = re.compile(r'https?://\\S+|www\\.\\S+|\\S+\\.(com|org|net|co|vn|io)(/\\S*)?')\n",
    "HTML_REGEX = re.compile(r\"<[^>]+>\")\n",
    "MENTION_REGEX = re.compile(r\"@[\\w\\._]+\")\n",
    "HASHTAG_REGEX = re.compile(r\"#\\w+\")\n",
    "UI_INDICATORS = [\n",
    "    \"đã chỉnh sửa\", \"[đã chỉnh sửa]\", \"(đã chỉnh sửa)\",\n",
    "    \"see more\", \"xem thêm\", \"see translation\", \"xem bản dịch\",\n",
    "    \"ẩn bớt\", \"xem ít hơn\", \"dịch\", \"translated\", \"more\", \"less\",\n",
    "    \"see more reactions\"\n",
    "]\n",
    "\n",
    "def remove_html_url_mention_hashtag(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Xóa URL\n",
    "    text = URL_REGEX.sub(\" \", text)\n",
    "    \n",
    "    # Xóa HTML tags\n",
    "    text = HTML_REGEX.sub(\" \", text)\n",
    "    \n",
    "    # Xóa mentions và hashtags\n",
    "    text = MENTION_REGEX.sub(\" \", text)\n",
    "    text = HASHTAG_REGEX.sub(\" \", text)\n",
    "    \n",
    "    # Xóa ui_indicators\n",
    "    for ind in UI_INDICATORS:\n",
    "        text = re.sub(r'(?i)' + re.escape(ind), \" \", text)\n",
    "    \n",
    "    # Loại bỏ dấu câu riêng lẻ\n",
    "    text = re.sub(r'(?<!\\w)[\\^\\'\\`\\~\\\"\\,\\.]+(?!\\w)', ' ', text)\n",
    "    \n",
    "    # Làm sạch khoảng trắng dư thừa\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reduce elongated characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.812810Z",
     "iopub.status.busy": "2025-08-08T10:38:12.812591Z",
     "iopub.status.idle": "2025-08-08T10:38:12.829665Z",
     "shell.execute_reply": "2025-08-08T10:38:12.828948Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.812791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reduce_elongated(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    pattern = regex.compile(r\"([\\p{L}])\\1{2,}\", flags=regex.IGNORECASE)\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lexical Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.830808Z",
     "iopub.status.busy": "2025-08-08T10:38:12.830471Z",
     "iopub.status.idle": "2025-08-08T10:38:12.869920Z",
     "shell.execute_reply": "2025-08-08T10:38:12.869431Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.830784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json, re\n",
    "\n",
    "# --- Load dict and build patterns ---\n",
    "with open('/kaggle/input/dictionary/abbreviation_dictionary.json', encoding='utf-8') as f:\n",
    "    norm_dict = json.load(f)\n",
    "\n",
    "mixed, pure, words = [], [], []\n",
    "for slang, std in norm_dict.items():\n",
    "    esc = re.escape(slang)\n",
    "    # classification\n",
    "    if re.fullmatch(r\"[^\\w\\s]+\", slang):\n",
    "        pure.append((esc, std))\n",
    "    elif re.search(r\"[^\\w\\s]\", slang) and re.search(r\"\\w\", slang):\n",
    "        mixed.append((esc, std))\n",
    "    else:\n",
    "        # add \\b for normal words\n",
    "        words.append((rf\"\\b{esc}\\b\", std))\n",
    "\n",
    "# sort desc\n",
    "for lst in (mixed, pure, words):\n",
    "    lst.sort(key=lambda x: -len(x[0].replace(r\"\\b\",\"\")))\n",
    "\n",
    "# compile \n",
    "_patterns = [\n",
    "    (re.compile(pat, flags=re.IGNORECASE), std)\n",
    "    for pat, std in (mixed + pure + words)\n",
    "]\n",
    "\n",
    "def apply_lexical_normalization(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    for regex, std in _patterns:\n",
    "        text = regex.sub(std, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.877925Z",
     "iopub.status.busy": "2025-08-08T10:38:12.877519Z",
     "iopub.status.idle": "2025-08-08T10:38:12.891047Z",
     "shell.execute_reply": "2025-08-08T10:38:12.890444Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.877908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VIET_CHARACTERS = (\n",
    "    \"àáảãạăằắẳẵặâầấẩẫậ\"\n",
    "    \"èéẻẽẹêềếểễệ\"\n",
    "    \"ìíỉĩị\"\n",
    "    \"òóỏõọôồốổỗộơờớởỡợ\"\n",
    "    \"ùúủũụưừứửữự\"\n",
    "    \"ỳýỷỹỵ\"\n",
    "    \"đ\"\n",
    ")\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Giữ chữ Việt + chữ Anh + số + space\n",
    "    text = regex.sub(rf\"[^{VIET_CHARACTERS}a-zA-Z0-9\\s]+\", \" \", text)\n",
    "    return regex.sub(r\"\\s+\", \" \", text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Whitespace Stripping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.891823Z",
     "iopub.status.busy": "2025-08-08T10:38:12.891634Z",
     "iopub.status.idle": "2025-08-08T10:38:12.903685Z",
     "shell.execute_reply": "2025-08-08T10:38:12.903091Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.891799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def strip_extra_spaces(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return regex.sub(r\"\\s+\", \" \", text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deduplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.904656Z",
     "iopub.status.busy": "2025-08-08T10:38:12.904428Z",
     "iopub.status.idle": "2025-08-08T10:38:12.916481Z",
     "shell.execute_reply": "2025-08-08T10:38:12.915894Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.904641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def deduplicate_comments(df, col):\n",
    "    before = len(df)\n",
    "    df_nodup = df.drop_duplicates(subset=[col]).reset_index(drop=True)\n",
    "    after = len(df_nodup)\n",
    "    return df_nodup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:12.917359Z",
     "iopub.status.busy": "2025-08-08T10:38:12.917127Z",
     "iopub.status.idle": "2025-08-08T10:38:52.629160Z",
     "shell.execute_reply": "2025-08-08T10:38:52.628529Z",
     "shell.execute_reply.started": "2025-08-08T10:38:12.917334Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 17,651 comments\n",
      "1. Normalizing Unicode and converting to lowercase\n",
      "2. Removing Remove Emoji,links/HTML/mentions/hashtags/UI indicators\n",
      "3. Reducing elongated characters\n",
      "4. Applying lexical normalization\n",
      "  Số dòng đã chỉnh sửa: 9,517/17,651 (53.92%)\n",
      "5. Removing all punctuation\n",
      "6. Whitespace Stripping\n",
      "7. Removing duplicate comments\n",
      "  Removed 350 duplicate comments\n",
      "\n",
      "==================================================\n",
      "Original comments:      17,651\n",
      "After filtering:        17,651 (100.0%)\n",
      "Final comments:         17,301 (98.0%)\n",
      "Total reduction:        350 comments (2.0%)\n",
      "\n",
      " Label Distribution:\n",
      "  • KHONG_LIEN_QUAN   : 8,886 (51.4%)\n",
      "  • KHONG_PHAN_DONG   : 6,202 (35.8%)\n",
      "  • PHAN_DONG         : 2,213 (12.8%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "selected_df = selected_df.copy()\n",
    "original_count = len(selected_df)\n",
    "print(f\"Starting with {original_count:,} comments\")\n",
    "\n",
    "# 1. Unicode normalization + lowercase\n",
    "print(\"1. Normalizing Unicode and converting to lowercase\")\n",
    "selected_df['comment_clean'] = selected_df['comment_raw'].apply(normalize_unicode_lower)\n",
    "\n",
    "# 2. Remove Emoji, links/HTML/mentions/hashtags/UI indicators\n",
    "print(\"2. Removing Remove Emoji,links/HTML/mentions/hashtags/UI indicators\")\n",
    "selected_df['comment_clean'] = selected_df['comment_clean'].apply(remove_emoji_emoticon)\n",
    "selected_df['comment_clean'] = selected_df['comment_clean'].apply(remove_html_url_mention_hashtag)\n",
    "\n",
    "# 3. Reduce elongated characters\n",
    "print(\"3. Reducing elongated characters\")\n",
    "selected_df['comment_clean'] = selected_df['comment_clean'].apply(reduce_elongated)\n",
    "\n",
    "# 4. Lexical normalization\n",
    "# print(\"4. Applying lexical normalization\")\n",
    "# selected_df['comment_clean'] = selected_df['comment_clean'].apply(apply_lexical_normalization)\n",
    "print(\"4. Applying lexical normalization\")\n",
    "before = selected_df['comment_clean'].copy()\n",
    "selected_df['comment_clean'] = selected_df['comment_clean'].apply(apply_lexical_normalization)\n",
    "\n",
    "num_lines_changed = (before != selected_df['comment_clean']).sum()\n",
    "percent_lines_changed = (num_lines_changed / len(selected_df)) * 100 if len(selected_df) else 0\n",
    "\n",
    "print(f\"  Số dòng đã chỉnh sửa: {num_lines_changed:,}/{len(selected_df):,} ({percent_lines_changed:.2f}%)\")\n",
    "# 5. Remove punctuation\n",
    "print(\"5. Removing all punctuation\")\n",
    "selected_df['comment_clean'] = selected_df['comment_clean'].apply(remove_punctuation)\n",
    "\n",
    "# 6. Whitespace Stripping\n",
    "print(\"6. Whitespace Stripping\")\n",
    "selected_df['comment_clean'] = selected_df['comment_clean'].apply(strip_extra_spaces)\n",
    "\n",
    "# 7. Deduplication\n",
    "print(\"7. Removing duplicate comments\")\n",
    "before_dedup = len(selected_df)\n",
    "selected_df = deduplicate_comments(selected_df, col='comment_clean')\n",
    "after_dedup = len(selected_df)\n",
    "print(f\"  Removed {before_dedup - after_dedup:,} duplicate comments\")\n",
    "\n",
    "# Statistics Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "final_count = len(selected_df)\n",
    "total_reduction = original_count - final_count\n",
    "retention_rate = (final_count / original_count) * 100\n",
    "reduction_rate = (total_reduction / original_count) * 100\n",
    "\n",
    "print(f\"Original comments:      {original_count:,}\")\n",
    "print(f\"After filtering:        {original_count:,} (100.0%)\")\n",
    "print(f\"Final comments:         {final_count:,} ({retention_rate:.1f}%)\")\n",
    "print(f\"Total reduction:        {total_reduction} comments ({reduction_rate:.1f}%)\")\n",
    "\n",
    "# Label Distribution\n",
    "if 'label' in selected_df.columns:\n",
    "    print(f\"\\n Label Distribution:\")\n",
    "    label_counts = selected_df['label'].value_counts().sort_index()\n",
    "    \n",
    "    for label, count in label_counts.items():\n",
    "        percentage = (count / final_count) * 100\n",
    "        print(f\"  • {label:<18}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:52.630223Z",
     "iopub.status.busy": "2025-08-08T10:38:52.629960Z",
     "iopub.status.idle": "2025-08-08T10:38:52.642981Z",
     "shell.execute_reply": "2025-08-08T10:38:52.642093Z",
     "shell.execute_reply.started": "2025-08-08T10:38:52.630199Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17301 entries, 0 to 17300\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   summary        17301 non-null  object\n",
      " 1   comment_raw    17301 non-null  object\n",
      " 2   label          17301 non-null  object\n",
      " 3   comment_clean  17301 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 540.8+ KB\n"
     ]
    }
   ],
   "source": [
    "selected_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T10:38:52.660139Z",
     "iopub.status.busy": "2025-08-08T10:38:52.659889Z",
     "iopub.status.idle": "2025-08-08T10:38:53.086793Z",
     "shell.execute_reply": "2025-08-08T10:38:53.086018Z",
     "shell.execute_reply.started": "2025-08-08T10:38:52.660114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned comments exported to: /kaggle/working/final_claened_new.csv\n"
     ]
    }
   ],
   "source": [
    "# Export\n",
    "output_path = \"/kaggle/working/final_claened_new.csv\"\n",
    "selected_df.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned comments exported to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7811352,
     "sourceId": 12564182,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7887000,
     "sourceId": 12709214,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
